# -*- coding: utf-8 -*-
"""Housing_EDA_notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d6wejjPFMz3UwKSOjNMKsF3uYyOIS0XJ

# EDA and pre-processing approach
## Steps
Use shape, info() and describe(include = 'all') to explain the data dimension and data types.
info()
Use info to explain which columns have wrong data types, which needs conversion:
* check if sold_price needs to be int
* Check if Bathrooms needs to be int
* Convert zipcode to object
* Convert year to object
* Explain number of null values also using info()

Column names and breif description for each column (a mini data dictionary).
  Mention units where applicable.

Report the number of duplicate records, if any.

Univariate analysis to explain distribution of numerical (use histogram and sns_kde plots) and categorical columns (frequency tables and bar plots).
  * lot_acres for example has (normal) distribution. There are 20 records, where lot_acres has 0 value. There are 12 outlier values of >1000. Explain that in data pre-processing step, you will impute 0 values, but leave the approach for data preprocessing step.

  * Similarly, year_built has 0 values.
  
  * For HOA, in addition to correlation with Sold_Price, check of correlation with taxes as well.

  * For bedrooms, provide a frequency table with below columns (order by Number of bedrooms)
  No_Bedrooms, Records_Count, Mean(Sqft), Mean(Sold_Price)

## Data pre-processing:
1. Remove duplicate rows, if any
2. Add City and State from zipcode (handle none values)
3. For sqft, add 2 new columns (Bedrooms_New, Sold_Price_Bin) to use as proxies for groupby to get mean value.
4. Remove missing values for other columns.
5. Impute 0 values in year_built and lot_acres
6. Create one-hot encoded columns for Kitchen_features and flooring
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

df = pd.read_excel('/content/drive/MyDrive/raw_house_data.xlsx')
print(df.shape)
print(df.describe())
df.head()

print(df['Lot_Acres'].quantile(0.9))
print(df['Sold_Price'].quantile(0.99))
print(df['Year_Built'].quantile(0.9))
print(df['Bedrooms'].quantile(0.99))
print(df['Bathrooms'].quantile(0.99))

print(df.info())
print(df.columns)

df = df.rename(columns = {'sold_price': 'Sold_Price', 'zipcode': 'Zipcode', 'longitude':'Longitude', 'latitude': 'Latitude', 'lot_acres': 'Lot_Acres',
       'taxes': 'Taxes', 'year_built': 'Year_Built', 'bedrooms': 'Bedrooms', 'bathrooms': 'Bathrooms', 'sqrt_ft':'Sqft', 'garage': 'Garage',
       'kitchen_features': 'Kitchen_Features', 'fireplaces': 'Fireplaces', 'floor_covering': 'Floor_Covering'})

missing = df.isnull().sum()
missing

# missing = missing[missing>0]
# missing.sort_values(inplace = True)
# missing.plot.bar()

ax = sns.barplot(missing, estimator="sum", errorbar=None)
ax.bar_label(ax.containers[0], fontsize=10);
plt.xticks(rotation=45)

missing

sns.heatmap(df[['Sold_Price', 'HOA']].corr(), cmap="BrBG", annot =True)

df = df.drop('HOA', axis = 1)
df.columns

sns.heatmap(df[['Bedrooms','Bathrooms', 'Sold_Price', 'Sqft']].corr(), cmap="BrBG", annot =True)



!pip install pyzipcode

from pyzipcode import ZipCodeDatabase

# Initialize the ZipCodeDatabase
zcd = ZipCodeDatabase()

# Function to get city and state based on zip code
def get_city_state(zipcode):
    try:
        zip_info = zcd[zipcode]
        return zip_info.city, zip_info.state
    except KeyError:
        # Handle invalid or non-existent zip codes
        return None, None

# Apply the function to add 'City' and 'State' columns
df[['City', 'State']] = df['Zipcode'].apply(lambda x: pd.Series(get_city_state(x)))

# Display the result
df.head()

df.groupby(['State', 'City'])['MLS'].count()

def create_price_bins(df, column_name='Sold_Price', num_bins=4, new_column_name='Sold_Price_Bin'):
    """
    Automatically creates bins for the specified column based on its distribution using pandas.qcut.

    Parameters:
        df (pd.DataFrame): The input DataFrame.
        column_name (str): The name of the column to bin.
        num_bins (int): The number of bins to create.
        new_column_name (str): The name of the new column with bin labels.

    Returns:
        pd.DataFrame: The DataFrame with an added column for the bins.
    """
    try:
        # Create bins using qcut
        df[new_column_name] = pd.qcut(df[column_name], q=num_bins, labels=[f'Bin_{i+1}' for i in range(num_bins)])
        return df
    except Exception as e:
        print(f"Error while creating bins: {e}")
        return df

# Convert 'Sqft' to numeric (this step is to convert None values to pandas NaN)
df['Sqft'] = pd.to_numeric(df['Sqft'], errors='coerce')

# Create price bins
df = create_price_bins(df, column_name='Sold_Price')
df.head()

### Step to add new column for Bedrooms where >8 is used for bedrooms with value greater than 8
# Define the bins and labels
bins = [0, 1, 2, 3, 4, 5, 6, 7, 8, float('inf')]  # >8 will go into the last bin
labels = ['1', '2', '3', '4', '5', '6', '7', '8', '>8']

# Create the new column 'Bedrooms_New' based on the bins
df['Bedrooms_New'] = pd.cut(df['Bedrooms'], bins=bins, labels=labels, right=True)
df.head()

df.groupby(['Bedrooms_New', 'Sold_Price_Bin'])['Sqft'].mean()

# Define a constant value for Bedrooms_New == 1
constant_value = 2086

# Step 1: Calculate the mean Sqft for each Bedrooms_New and Sold_Price_Bin group
mean_sqft = df.groupby(['Bedrooms_New', 'Sold_Price_Bin'])['Sqft'].transform('mean')

# Step 2: Impute NaN values based on the group means or constant value for Bedrooms_New == 1
df['Sqft'] = df['Sqft'].fillna(df.apply(
    lambda row: constant_value if row['Bedrooms_New'] == '1' else mean_sqft[row.name], axis=1
))

df.head()

df = df.dropna()

dtype_mapping = {
    'Year_Built': 'object',
    'Bedrooms': 'int64',
    'Bathrooms': 'int64',
    'Sold_Price': 'int64',
    'Garage':'int64'
}

df = df.astype(dtype_mapping)

print(df.dtypes)

### Need to encode the Kitchen_Features column which is helpful for modelling
# Create a features list with all unique values from Kitchen_Features column

features = set(
    feature.strip()
    for item in df["Kitchen_Features"].dropna()
    for feature in item.split(",")
)

len(features)

for feature in features:
  df[feature] = df['Kitchen_Features'].apply(lambda x: 1 if isinstance(x, (list, str)) and feature in x else 0)

df.head()

### Need to encode the Floor_Covering column which is helpful for modelling
# Create a floors list with all unique values from Floor_Covering column


floors = set(
    floor.strip()
    for item in df["Floor_Covering"].dropna()  # Drop NaN values
    for floor in item.split(",")
)

print(floors)

len(floors)

for floor in floors:
  df[floor] = df['Floor_Covering'].apply(lambda x: 1 if isinstance(x, (list, str)) and floor in x else 0)

df.head()

import seaborn as sns

plt.hist(df['Lot_Acres'], bins = 20)
##Lot_Acres values cant be zero

fig, axes = plt.subplots(1, 2, figsize=(10, 5))

# Original data
sns.boxplot(data=df['Lot_Acres'], showfliers=True, ax=axes[0])
axes[0].set_title("Original Distribution")
axes[0].set_ylabel("Lot_Acres")

# Distribution without outliers
sns.boxplot(data=df['Lot_Acres'], showfliers=False, ax=axes[1])
axes[1].set_title("Distribution without outliers")
axes[1].set_ylabel("Lot_Acres")

plt.tight_layout()
plt.show()

import numpy as np

# Example: Log transformation
original_data = df['Sold_Price']
transformed_data = np.log1p(df['Sold_Price'])

# Adding key statistics to the plot
mean_val = original_data.mean()
median_val = np.median(original_data)

sns.histplot(original_data, kde=True, bins=50, color='skyblue', alpha=0.6)
plt.axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')
plt.axvline(median_val, color='orange', linestyle='-', label=f'Median: {median_val:.2f}')
plt.legend()
plt.title("Sold_Price - Distribution")
plt.xlabel("Original Distribution")
plt.ylabel("Frequency")
plt.show()

df = df[df['Year_Built']!=0]

# sns.histplot(df['Year_Built'], bins = 20, kde=True)

# Adding key statistics to the plot
# mean_val = df['Year_Built'].mean()
median_val = np.median(df['Year_Built'])

sns.histplot(df['Year_Built'], kde=True, bins=30, color='lightcoral', alpha=0.6)
# plt.axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')
plt.axvline(median_val, color='orange', linestyle='-', label=f'Median: {median_val:.0f}')
plt.legend()
plt.title("Year_Built - Distribution")
plt.xlabel("Original Distribution")
plt.ylabel("Frequency")
plt.show()

# Adding key statistics to the plot
mean_val = df['Bedrooms'].mean()
median_val = np.median(df['Bedrooms'])

sns.histplot(df['Bedrooms'], kde=True, bins=30, color='lightcoral', alpha=0.6)
plt.axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')
plt.axvline(median_val, color='orange', linestyle='-', label=f'Median: {median_val:.0f}')
plt.legend()
plt.title("Bedrooms - Distribution")
plt.xlabel("Original Distribution")
plt.ylabel("Frequency")
plt.show()

# Adding key statistics to the plot
# # mean_val = df['Bedrooms_New'].mean()
# median_val = np.median(df['Bedrooms_New'])

sns.histplot(df['Bedrooms_New'], kde=True, bins=30, color='lightcoral', alpha=0.6)
# plt.axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')
# plt.axvline(median_val, color='orange', linestyle='-', label=f'Median: {median_val:.0f}')
# plt.legend()
plt.title("Bedrooms_New - Distribution")
plt.xlabel("Original Distribution")
plt.ylabel("Frequency")
plt.show()

# Adding key statistics to the plot
mean_val = df['Bathrooms'].mean()
median_val = np.median(df['Bathrooms'])

sns.histplot(df['Bathrooms'], kde=True, bins=30, color='skyblue', alpha=0.6)
plt.axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')
plt.axvline(median_val, color='orange', linestyle='-', label=f'Median: {median_val:.0f}')
plt.legend()
plt.title("Bathrooms - Distribution")
plt.xlabel("Original Distribution")
plt.ylabel("Frequency")
plt.show()

df.head()

df_correlation = df[['Sold_Price', 'Lot_Acres', 'Taxes', 'Sqft', 'Bedrooms', 'Bathrooms']].corr()

sns.heatmap(df_correlation, annot=True)

df.to_csv('housing_data_cleaned.csv')

